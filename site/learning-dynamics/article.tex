\documentclass[11pt]{article}
 
\usepackage[utf8]{inputenc}      
\usepackage[T1]{fontenc}          
\usepackage{lmodern}              
\usepackage{amsmath, amssymb}    
\usepackage{graphicx}             
\usepackage{hyperref}             
\usepackage{geometry}             
\usepackage{cite}              

\geometry{a4paper, margin=1in}

\title{Learning Dynamics}
\author{Eric Hermosis \\ \texttt{eric.hermosis@gmail.com}}

\date{\today}

\begin{document}

\maketitle

\begin{abstract}
The work presents a fundamental theory of artificial learning that aims to explain existing optimization algorithms and support the development of new ones. It is based on a thermodynamic framework, using geometric and Hamiltonian formalisms to derive the evolution equations of learning models. These equations provide a physical grounding for the learning process and show that learning can be understood as a thermodynamic process in which models evolve according to the information they perceive.
\end{abstract}

\section*{Introduction}

This work aims to develop a fundamental theory of artificial learning that both explains existing optimization algorithms and facilitates their improvement as well as the creation of new ones. To this end, only three assumptions were made about a model capable of learning:

\begin{itemize}
    \item It can be described by a finite set of parameters.
    \item It is differentiable with respect to its parameters.
    \item It makes no assumptions about the information it ingests.
\end{itemize}

The theory is constructed based on the axiomatic thermodynamic framework proposed by Callen~\cite{callen_thermo}. Assuming a quasi-static regime, symplectic geometry is used to describe the geometry of the model’s phase space~\cite{cannas_symph}, and a Hamiltonian formalism~\cite{arnold_mechanics} is employed to derive the model’s equations of evolution.

Finally, we utilize these equations to re-derive established optimization algorithms, thereby validating the theory and offering a physical grounding for the learning process. This shows that algorithms like momentum-based Stochastic Gradient Descent~\cite{bishop_dl} or regularization techniques like Weight Decay~\cite{krogh_weight_decay} emerge naturally as consequences of the proposed equations of learning.

The connection between the concepts of information and entropy~\cite{baez_entropy} suggests that learning can be modeled as a thermodynamic process, in which its participants, known as models, evolve based on the information they perceive.

\section*{Modeling}

A model is a simplified representation of a system, defined by a set of parameters that determine its behavior. A specific choice of a set of parameters defines what we will call a \emph{configuration}.

We say that a model is differentiable if its configurations are points on a smooth differential manifold $\mathcal{S}$ such that its learning can be defined in terms of a curve parametrized over it~\cite{lee_smooth}.

On the other hand, we will only focus on models that are domain-agnostic, meaning they do not incorporate assumptions about the information they will ingest. In this way, the dynamics of their learning can be designed solely in terms of their configurations.

\section*{Equilibrium}

To each dimension of the manifold, we can associate a parameter so that each configuration $s \in \mathcal{S}$ can be described in terms of coordinates:

\begin{equation}
(U/c, w^1, \dots, w^d) = (w^0, \mathbf{w}) \in \mathbb{R}^{d+1},
\end{equation}

where $U$ represents the internal energy, $w^1, \dots, w^d$ are extensive parameters of the model known as weights, and $c$ is a constant such that $w^0$ is dimensionless.

We say that the model is in an equilibrium state~\cite{callen_thermo} if an entropy function $S$ can be defined over it, with units of information, and monotonically increasing with respect to energy, that is:

\begin{equation}
\frac{\partial S}{\partial U} > 0.
\end{equation}

By differentiating $S$, we can see how it changes under infinitesimal displacements of the configuration:

\begin{equation}
dS = \frac{\partial S}{\partial U} dU + \sum_{j} \frac{\partial S}{\partial w^{j}} dw^{j}.
\end{equation}

The rates of change of entropy along the directions of energy and weights give rise to the conjugate variables:

\begin{equation}
\beta = \frac{\partial S}{\partial U}, \qquad Y_{j} = \frac{\partial S}{\partial w^{j}}, \qquad j = 1, \dots, d.
\end{equation}

These variables are known as the intensive parameters of the model. We will refer to the $\mathbf{Y}$ intensive parameters as \emph{entropic moments}. We can also identify the temperature $T$ as the reciprocal of the parameter $\beta$ conjugate to the energy, that is:

\begin{equation}
T \equiv \frac{1}{\beta} > 0.
\end{equation}

The entropy function is local, that is, it is only defined for each equilibrium state. Therefore, if one seeks to describe the states of the model over the entire state space, it is necessary to resort to the phase space~\cite{arnold_mechanics} defined over $\mathcal{S}$.

The phase space is a construction over the state space that assigns to each point its cotangent space; that is, if $(w_0, \mathbf{w})$ are coordinates of the state space, then $(w_0, \mathbf{w}, Y^0, \mathbf{Y})$ are coordinates of the phase space. Let us now consider the 1-form living in the phase space $\Omega$ given by:

\begin{equation}
\omega = \beta \, dU + \sum_{j} Y_{j} \, dw^{j} \in \Omega.
\end{equation}

This form generalizes the notion of the differential of entropy, such that the model is in an equilibrium state if there exists an entropy function $S$ such that:

\begin{equation}
\omega = dS.
\end{equation}

Expanding the exterior derivative of the differential 1-form $\omega$, we obtain the differential 2-form:

\begin{equation}
d\omega = d\beta \wedge dU + \sum_{j} dY_{j} \wedge dw^{j}.
\end{equation}

The latter is known as the \emph{symplectic form}~\cite{cannas_symph} and allows the phase space $\Omega$ to be endowed with a Hamiltonian geometric structure.

\section*{Evolution}

For each point in the phase space, entropy is defined only for equilibrium states. This means that, to remain within the scope of a thermodynamic description, the system's evolution must be slow enough to preserve the quasi-static approximation. Under this approximation, the learning curve can be viewed as a succession of equilibrium states. This approximation allows us to define canonical pairs over the entire manifold through Poisson brackets:

\begin{equation}
\{U, \beta\} = 1, \qquad \{w^{i}, Y_{j} \} = \delta^{i}_{j}, \qquad \text{with } \delta^{i}_{j} =
\begin{cases} 
1 & i = j \\ 
0 & i \neq j 
\end{cases}.
\end{equation}

Then, we can recover an analogue to Hamilton's equations~\cite{hamilton1834} for thermodynamic parameters to describe the evolution of the model parameters without constraints:

\begin{equation}
-h \frac{dw^{i}}{dt} = k\{w^{i}, H\} = k\frac{\partial H}{\partial Y_{i}}, \qquad -\frac{dY_{i}}{dt} = k\{Y_{i}, H  \} = -k\frac{\partial H}{\partial w^{i}},
\end{equation}

\begin{equation}
-\frac{dU}{dt} = k\{U, H \} = k\frac{\partial H}{\partial \beta}, \qquad -h\frac{d\beta}{dt} = k\{\beta, H\} = -k\frac{\partial H}{\partial U},
\end{equation}

where $h$ is the unit of action and $k$ is the unit of information, introduced to maintain consistent units.

The problem with this formulation is that it leads to dynamics in which the model evolves in closed orbits. To address this, we introduce a coupling of the intensive parameters with the temperature of the form:

\begin{equation}
Y_{i} = \beta X_{i}, \qquad i = 1, \dots, d.
\end{equation}

We will refer to the $\mathbf{X}$ parameters as \emph{energy moments}. This coupling is not arbitrary; rather, it arises directly from the energy representation of thermodynamics:

\begin{equation}
dU = T \, dS - \sum_{j} X_{j} \, dw^{j}.
\end{equation}

The coupling deforms the symplectic structure that describes the geometry of the phase space. By substituting the coupling into the 2-form $d\omega$, we obtain:

\begin{equation}
d\omega = d\beta \wedge \Bigl(dU + \sum_{j} X_{j} \, dw^{j}\Bigr) + \beta \sum_{j} dX_{j} \wedge dw^{j},
\end{equation}

which remains a non-degenerate symplectic form for $\beta > 0$, a condition already imposed. The new non-negative Poisson brackets yield:

\begin{equation}
\{U, \beta \} = 1, \qquad \{w^{i}, X_{j}\} = \delta^{i}_j, \qquad \{U, X_{i}\} = -\frac{1}{\beta} X_{i}.
\end{equation}

Their respective equations of motion are given by:

\begin{equation}
-h\frac{dw^{i}}{dt} = \frac{k}{\beta} \frac{\partial H}{\partial X_{i}}, \qquad -h\frac{dX_{i}}{dt} = -\frac{k}{\beta} \frac{\partial H}{\partial w^{i}} + \frac{k X_{i}}{\beta} \frac{\partial H}{\partial U},
\end{equation}

\begin{equation}
-h\frac{dU}{dt} = k \frac{\partial H}{\partial \beta} - \frac{k}{\beta} \sum_{j} X_{j} \frac{\partial H}{\partial X_{j}}, \qquad -h\frac{d\beta}{dt} = -k\frac{\partial H}{\partial U}.
\end{equation}

We will refer to these as the \emph{Hermosis equations of learning}. While they can be rigorously derived from the new symplectic form, a more streamlined derivation based on the properties of Poisson brackets is provided in the Appendix.


\section*{Integration}

The presented four equations allow us to describe the learning process of a model. Since they must be numerically integrated to perform optimization, we seek their integral form. By substituting the last equation into the second one and rearranging terms, we obtain the evolution equation for the momenta $X_i$ as:

\begin{equation}
h \beta \frac{dX_{i}}{dt} + h \frac{d\beta}{dt} X_{i} = h \frac{d}{dt} (\beta X_{i}) = k \frac{\partial H}{\partial w^{i}}.
\end{equation}

Integrating over the interval $[t-\tau, t]$, we obtain an update rule for the momenta:

\begin{equation}
\beta(t) \mathbf{X}(t) = \beta(t-\tau) \mathbf{X}(t-\tau) - \int_{t-\tau}^{t} \mathbf{F}(t') \, dt',
\end{equation}

where $\mathbf{F}$ represents a generalized force, whose components are given by:

\begin{equation}
F_{i} = -\frac{k}{h} \frac{\partial H}{\partial w^{i}}.
\end{equation}

On the other hand, integrating the first equation over the same interval, we obtain an update rule for the weights:

\begin{equation}
\mathbf{w}(t) = \mathbf{w}(t-\tau) - \int_{t-\tau}^{t} \mathbf{v}(t') \, dt',
\end{equation}

where $\mathbf{v}$ denotes the learning velocity, with components:

\begin{equation}
v^{i} = \frac{k}{h \beta} \frac{\partial H}{\partial X_{i}}.
\end{equation}

This last equation highlights an important point: the parameter $\beta$ determines the system's inertia throughout its evolution. Large values of $\beta$ slow down learning, while small values accelerate it.

\section{Application}

Let us now examine the connection between the proposed dynamics and current algorithms used in machine learning.

In practice, a model is trained by minimizing a loss function $L$, which measures the distance between a model's current state and an expected state. Drawing from classical mechanics, we propose a potential analogous to the gravitational potential:

\begin{equation}
V = \frac{\beta c^2}{k} L,
\end{equation}

where $c^2$, with units of square energy, is introduced to ensure that $L$ remains dimensionless. The choice of this potential is not arbitrary; it is based on the interpretation of the term $\beta/k$ as a thermal mass that amplifies the importance of the distance within the potential energy. Furthermore, we propose a kinetic energy in terms of a mass tensor $M_{ij}$ of the form:

\begin{equation}
K = \frac{1}{2} \sum_{ij} M^{ij} Y_{i} Y_{j} = \frac{\beta}{2k} \sum_{ij} g^{ij} X_{i} X_{j} = \frac{\beta}{2k} \mathbf{X}^2,
\end{equation}

where $g_{ij}$ is a dimensionless metric tensor, assumed for the moment to be constant. In this way, the Hamiltonian is defined as:

\begin{equation}
H = \frac{\beta}{2k} \mathbf{X}^2 + \frac{\beta c^2}{k} L + E(U, \beta),
\end{equation}

where $E$ is a function of the temperature, enabling specification of an arbitrary thermal profile. Under this Hamiltonian, the velocity components are:

\begin{equation}
v^{i} = \frac{k}{h \beta} \frac{\partial H}{\partial X_{i}} = \frac{1}{h} X^{i}, \qquad X^{i} = \sum_{j} g^{ij} X_j.
\end{equation}

Applying an Euler discretization, the weight update rule can be approximated as:

\begin{equation}
\mathbf{w}(t) \approx \mathbf{w}(t-\tau) - \frac{\tau}{h} \mathbf{X}(t).
\end{equation}

The generalized force driving the learning process has components:

\begin{equation}
F_{i} = -\frac{\beta c^2}{h} \frac{\partial L}{\partial w^{i}}.
\end{equation}

Evaluating the components and integrating, we obtain the impulse as a function of the loss gradient:

\begin{equation}
\mathbf{I}(t) = -\int_{t-\tau}^{t} \mathbf{F}(t') \, dt' = \frac{c^2}{h} \nabla L \int_{t-\tau}^{t} \beta(t') \, dt'.
\end{equation}

Substituting into the momentum update rule:

\begin{equation}
\mathbf{X}(t) = \frac{\beta(t-\tau)}{\beta(t)} \mathbf{X}(t-\tau) + \frac{c^2}{h} \left( \frac{1}{\beta(t)} \int_{t-\tau}^{t} \beta(t') \, dt' \right) \nabla L.
\end{equation}

Assuming a constant temperature, $\beta(t) = \beta$, we obtain:

\begin{equation}
\mathbf{I}(t) = \frac{\tau c^2}{h} \beta \nabla L, \qquad 
\mathbf{X}(t) = \mathbf{X}(t-\tau) + \frac{\tau c^2}{h} \nabla L.
\end{equation}

Under suitable reparameterization, we recover the standard gradient descent or SGD update rule~\cite{bishop_dl}:

\begin{equation}
\begin{aligned}
\mathbf{X}(t) &= \mathbf{X}(t-\tau) + \zeta \nabla L, \\
\mathbf{w}(t) &\approx \mathbf{w}(t-\tau) - \eta \mathbf{X}(t),
\end{aligned}
\end{equation}

where $\eta$ is the learning rate and $\zeta$ controls the influence of the loss gradient on momentum.

By adding a harmonic potential to the Hamiltonian:

\begin{equation}
H = \frac{\beta}{2k} \mathbf{X}^2 + \frac{\lambda}{2} \mathbf{w}^2 + V,
\end{equation}

the generalized force now includes a term consistent with gradient descent with weight decay~\cite{krogh_weight_decay}:

\begin{equation}
F'_{\alpha} = \lambda w_{\alpha}.
\end{equation}

Assuming an exponentially growing thermal mass, $\beta(t) = \beta e^{\gamma t}$, the impulse becomes:

\begin{equation}
\mathbf{I}(t) = \frac{c^2}{h} \frac{1-e^{-\gamma \tau}}{\gamma} \beta e^{\gamma t} \nabla L,
\end{equation}

leading to momenta as an exponential moving average~\cite{brown_expsmooth}:

\begin{equation}
\mathbf{X}(t) = e^{-\gamma \tau} \mathbf{X}(t-\tau) + \frac{1-e^{-\gamma \tau}}{\gamma} \frac{c^2}{h} \nabla L.
\end{equation}

Under reparameterization, this recovers gradient descent with momentum and friction~\cite{bottou_sgd}:

\begin{equation}
\begin{aligned}
\mathbf{X}(t) &= \mu \mathbf{X}(t-\tau) + (1-\mu) \zeta \nabla L, \\
\mathbf{w}(t) &= \mathbf{w}(t-\tau) - \eta \mathbf{X}(t).
\end{aligned}
\end{equation}

Finally, adopting a relativistic kinetic energy Hamiltonian:

\begin{equation}
H = \sqrt{\mathbf{X}^2 + \frac{k^2}{\beta^2}} + V + E(U, \beta),
\end{equation}

which reduces to the classical case for $|\mathbf{X}| \ll k/\beta$:

\begin{equation}
\sqrt{\mathbf{X}^2+\frac{k^2}{\beta^2}} \approx \frac{k}{\beta} + \frac{\beta}{2k}\mathbf{X}^2 - \frac{\beta^3 (\mathbf{X}^2)^2}{8k^3} + \dots
\end{equation}

The corresponding learning velocity is:

\begin{equation}
v^{i} = \frac{k}{h \beta} \frac{\partial H}{\partial X_{i}} = \frac{1}{h} \frac{X^{i}}{\sqrt{\beta^2 \mathbf{X}^2/k^2 + 1}}.
\end{equation}

For constant $\beta$, this recovers relativistic gradient descent~\cite{franca_conformal}:

\begin{equation}
\mathbf{w}(t) = \mathbf{w}(t-\tau) - \eta \frac{\mathbf{X}}{\sqrt{\mathbf{X}^2 + k^2/\beta^2}}.
\end{equation}

Embedding the potential into the metric tensor, following Guskov and Vanchurin~\cite{guskov_covariant}, recovers adaptive momentum-based optimizers such as Adam~\cite{kingma_adam} and, as a special case, RMSProp~\cite{hinton_nn}. Explicit verification within this framework remains as future work.

\section*{Conclusion}

The proposed formalism demonstrates that a Hamiltonian framework can recover the majority of current optimization algorithms. This approach moves beyond purely heuristic updates, offering a clear physical interpretation where:

\begin{itemize}
    \item The loss function acts as a metric distance between system configurations.
    \item Temperature dictates the effective mass, weighting the importance of these distances.
    \item Phase space convergence is guaranteed by the evolution of internal energy.
\end{itemize}

These results lay the groundwork for a new class of physically-informed optimizers. By identifying where current classical approximations fail, such as the decoupling of the potential from the metric tensor, we open new avenues for incorporating covariant and relativistic dynamics into machine learning, potentially leading to more stable and faster convergence in complex loss landscapes.

\newpage

\section*{Apendix: Derivation of Learning Equations}

The equations for the system without temperature coupling, described by the variables $\mathbf{Y}$, are:

\begin{equation}
-h \frac{dw^{i}}{dt} = k\{w^{i}, H\} = k\frac{\partial H}{\partial Y_{i}}, \qquad 
-\frac{dY_{i}}{dt} = k\{Y_{i}, H\} = -k\frac{\partial H}{\partial w^{i}},
\end{equation}

\begin{equation}
-\frac{dU}{dt} = k\frac{\partial H}{\partial \beta}, \qquad -h\frac{d\beta}{dt} = -k\frac{\partial H}{\partial U}.
\end{equation}

We now derive the equations with the coupling $\mathbf{Y} = \beta \mathbf{X}$. From the Leibniz rule for the bracket containing the coordinates of $\mathbf{Y}$, given a Hamiltonian $H$:

\begin{equation}
\{Y_{i}, H\} = \{\beta X_{i}, H\} = \beta \{X_{i}, H\} + X_{i} \{\beta, H\}.
\end{equation}

Given that we know:

\begin{equation}
\{Y_{i}, H\} = -\frac{\partial H}{\partial w^{i}}, \qquad \{\beta, H\} = -\frac{\partial H}{\partial U},
\end{equation}

we substitute these values to obtain the Poisson brackets of the system in terms of the momenta $\mathbf{X}$:

\begin{equation}
-\frac{\partial H}{\partial w^{i}} = \beta \{X_{i}, H\} - X_{i} \frac{\partial H}{\partial U} \quad \Rightarrow \quad 
\{X_{i}, H\} = -\frac{1}{\beta} \frac{\partial H}{\partial w^{i}} + \frac{X_{i}}{\beta} \frac{\partial H}{\partial U}.
\end{equation}

We then recover the proposed H-equation:

\begin{equation}
-h \frac{dX_{i}}{dt} = k \{X_{i}, H\} = -\frac{k}{\beta} \frac{\partial H}{\partial w^{i}} + \frac{k X_{i}}{\beta} \frac{\partial H}{\partial U}.
\end{equation}

To reconcile the evolution of the internal energy with the proposed evolution, we recall the thermodynamic identity:

\begin{equation}
\left(\frac{\partial H}{\partial \beta} \right)_{\mathbf{Y}} =  
\left(\frac{\partial H}{\partial \beta} \right)_{\mathbf{X}} + \sum_{j} \left(\frac{\partial H}{\partial X_{j}} \right)_{\beta, X_{i \neq j}} \left(\frac{\partial X_{j}}{\partial \beta} \right)_{\mathbf{Y}},
\end{equation}

where the subscripts indicate which parameters are considered constant.

From the coupling relation:

\begin{equation}
X_{i} = \frac{Y_{i}}{\beta} \quad \Rightarrow \quad \frac{\partial X_{i}}{\partial \beta} = -\frac{1}{\beta^2} Y_{i} = -\frac{1}{\beta} X_{i},
\end{equation}

we obtain the evolution of the internal energy:

\begin{equation}
-h \frac{dU}{dt} = k \frac{\partial H}{\partial \beta} - \frac{1}{\beta} \sum_{j} \frac{\partial H}{\partial X_{j}} X_{j}.
\end{equation}

For the weight-momentum brackets:

\begin{equation}
\frac{\partial H}{\partial Y_{i}} = \frac{\partial H}{\partial X_{i}} \frac{\partial X_{i}}{\partial Y_{i}} = \frac{1}{\beta} \frac{\partial H}{\partial X_{i}}.
\end{equation}

Then:

\begin{equation}
-h \frac{dw^{i}}{dt} = \frac{k}{\beta} \frac{\partial H}{\partial X_{i}}.
\end{equation}

Finally, the equation containing the changes of $H$ in the direction $\partial/\partial U$ remains identical, since the variable $U$ is not coupled in the same way as $\beta$.


\bibliographystyle{unsrt} 
\bibliography{refs}       

\end{document}