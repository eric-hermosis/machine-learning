{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome!","text":"<p>This website is dedicated to sharing my ongoing theoretical research in machine learning. It is intended as a living repository of ideas, evolving over time as I expand on my work.  </p> <p>Here, you will find a series of individual notes, preprints and publications that explore various aspects of modern machine learning theory under a physics perspective. Each article is meant to stand on its own but collectively, they aim to grow into a cohesive, evolving \u201cliving book\u201d of machine learning insights.</p>"},{"location":"#topics","title":"Topics","text":"<ul> <li> <p>Learning Dynamics </p> <p>The work presents a fundamental theory of artificial learning as a thermodynamic process in which models evolve according to the information they perceive. </p> </li> </ul>"},{"location":"#contribute","title":"Contribute","text":"<p>Contributions to this repository are warmly welcome, whether in the form of suggestions, corrections, or extensions to the research, or improvements of the website itself. All contributions will be acknowledged here to recognize your support in advancing this evolving body of work.</p> <p>If you have questions or suggestions, please feel free to email me at eric.hermosis@gmail.com. Your feedback is highly valued and can help improve the clarity and depth of the work.</p> <p>Thank you for visiting, and I hope you find these ideas thought-provoking and useful in understanding the theoretical aspects of deep learning.</p>"},{"location":"learning-dynamics/","title":"Learning Dynamics","text":""},{"location":"learning-dynamics/#introduction","title":"Introduction","text":"<p>This work aims to develop a fundamental theory of artificial learning that both explains existing optimization algorithms and facilitates their improvement as well as the creation of new ones. To this end, only three assumptions were made about a model capable of learning:</p> <ul> <li> <p>It can be described by a finite set of parameters.</p> </li> <li> <p>It is differentiable with respect to its parameters.</p> </li> <li> <p>It makes no assumptions about the information it ingests.</p> </li> </ul> <p>The theory is constructed based on the axiomatic thermodynamic framework proposed by Callen <sup>1</sup>. Assuming a quasi-static regime, symplectic geometry is used to describe the geometry of the model\u2019s phase space <sup>2</sup>, and a Hamiltonian formalism <sup>3</sup> is employed to derive the model\u2019s equations of evolution.</p> <p>Finally, we utilize these equations to re-derive established optimization algorithms, thereby validating the theory and offering a physical grounding for the learning process. This shows that algorithms like momentum-based Stochastic Gradient Descent <sup>4</sup> or regularization techniques like Weight Decay <sup>5</sup>, emerge naturally as consequences of the proposed equations of learning.</p>"},{"location":"learning-dynamics/#model","title":"Model","text":"<p>The connection between the concepts of information and entropy <sup>6</sup> suggests that learning can be modeled as a thermodynamic process, in which its participants, known as models, evolve based on the information they perceive.</p> <p>A model is a simplified representation of a system, defined by a set of parameters that determine its behavior. A specific choice of a set of parameters defines what we will call a configuration.</p> <p>We say that a model is differentiable if its configurations are points on a smooth differential manifold such that its learning can be defined in terms of a curve parametrized over it. <sup>7</sup></p> <p>On the other hand, we will only focus on models that are domain-agnostic, meaning they do not incorporate assumptions about the information they will ingest. In this way, the dynamics of their learning can be designed solely in terms of their configurations.</p>"},{"location":"learning-dynamics/#equilibrium","title":"Equilibrium","text":"<p>Let's consider a differentiable model whose parameters reside in a smooth manifold \\(S\\). For each dimension of the manifold, we can associate a parameter so that each configuration \\(s \\in \\mathcal{S}\\) can be described in terms of coordinates.</p> \\[ (U/c, w^1, ..., w^d) = (w^0, \\mathbf{w}) \\in \\mathbb{R}^{d+1} \\] <p>Where \\(U\\) represents the internal energy, \\(w^1, \\dots, w^d\\) are extensive parameters of the model known as weights, and \\(c\\) is a constant such that \\(w^0\\) is dimensionless.</p> <p>We say that the model is in an equilibrium state <sup>1</sup> if an entropy function \\(S\\) can be defined over it, with units of information, and monotonically increasing with respect to energy, that is:</p> \\[ \\frac{\\partial S}{\\partial U} &gt; 0 \\] <p>By differentiating \\(S\\), we can see how it changes under infinitesimal displacements of the configuration:</p> \\[ dS = \\frac{\\partial S}{\\partial U} dU + \\sum_{j} \\frac{\\partial S}{\\partial w^{j}}dw^{j} \\] <p>The rates of change of entropy along the directions of energy and weights give rise to the conjugate variables:</p> \\[ \\beta = \\frac{\\partial S}{\\partial U} \\qquad Y_{j} = \\frac{\\partial S}{\\partial w^{j}} \\qquad j = 1,...,d \\] <p>These variables are known as the intensive parameters of the model. We will refer to the \\(\\mathbf{Y}\\) intensive parameters as entropic moments. We can also identify the temperature \\(T\\) as the reciprocal of the parameter \\(\\beta\\) conjugate to the energy, that is:</p> \\[ T \\equiv \\frac{1}{\\beta} &gt; 0  \\] <p>The entropy function is local, that is, it is only defined for each equilibrium state. Therefore, if one seeks to describe the states of the model over the entire state space, it is necessary to resort to the phase space <sup>3</sup> defined over \\(\\mathcal{S}\\). </p> <p>The phase space is a construction over the state space that assigns to each point its cotangent space; that is, if \\((w_0, \\mathbf{w})\\) are coordinates of the state space, then \\((w_0, \\mathbf{w},Y^0, \\mathbf{Y})\\) are coordinates of the phase space. Let us now consider the \\(1\\)-form living in the phase space \\(\\Omega\\) given by:</p> \\[ \\omega = \\beta dU + \\sum_{j} Y_{j} dw^{j} \\in \\Omega \\] <p>This form generalizes the notion of the differential of entropy, such that the model is in an equilibrium state if there exists an entropy function \\(S\\) such that:</p> \\[ \\omega = dS \\] <p>Expanding the exterior derivative of the differential \\(1\\)-form \\(\\omega\\), we obtain the differential \\(2\\)-form:</p> \\[ d\\omega = d\\beta \\wedge dU + \\sum_{j} dY_{j} \\wedge dw^{j} \\] <p>The latter is known as the symplectic form <sup>2</sup> and allows the phase space \\(\\Omega\\) to be endowed with a Hamiltonian geometric structure.</p>"},{"location":"learning-dynamics/#evolution","title":"Evolution","text":"<p>For each point in the phase space, entropy is defined only for equilibrium states. This means that, to remain within the scope of a thermodynamic description, the system's evolution must be slow enough to preserve the quasi-static approximation, then the learning curve can be viewed as a succession of equilibrium states what allows us to define canonical pairs over the entire manifold through Poisson brackets:</p> \\[ \\{U, \\beta\\} = 1 \\qquad \\{w^{i}, Y_{j} \\} = \\delta^{i}_{j} \\qquad \\text{with } \\delta^{i}_{j} = \\begin{cases} 1 \\quad i = j \\\\ 0 \\quad i \\neq j \\end{cases}  \\] <p>Then, we can recover an analogue to Hamilton's equations <sup>8</sup> for thermodynamic parameters to describe the evolution of the model parameters without constraints:</p> \\[ -h \\frac{dw^{i}}{dt} = k\\{w^{i}, H\\} = k\\frac{\\partial H}{\\partial Y_{i}} \\qquad -\\frac{dY_{i}}{dt} = k\\{Y_{i}, H  \\} = -k\\frac{\\partial H}{\\partial w^{i}} \\] \\[ -\\frac{dU}{dt} = k\\{U, H \\} = k\\frac{\\partial H}{\\partial \\beta} \\qquad -h\\frac{d\\beta}{dt} = k\\{\\beta, H\\} = -k\\frac{\\partial H}{\\partial U} \\] <p>Where \\(h\\) is the unit of action and \\(k\\) is the unit of information, which are introduced to maintain consistent units.</p> <p>The problem with this formulation is that it leads to a dynamics in which the model evolves in closed orbits. To address this, we introduce a coupling of the intensive parameters with the temperature of the form:</p> \\[ Y_{i} = \\beta X_{i} \\qquad i = 1, ..., d \\] <p>We will refer to the \\(\\mathbf{X}\\) parameters as energy moments. This coupling is not arbitrary, rather, it arises directly from the energy representation of thermodynamics:</p> \\[ dU = T dS - \\sum_{j} X_{j} dw^{j} \\] <p>The coupling deforms the symplectic structure that describes the geometry of the phase space. By substituting the coupling into the \\(2\\)-form \\(d\\omega\\), we obtain:</p> \\[ d\\omega = d\\beta \\wedge (dU +\\sum_{j}X_{j}dw^{j}) + \\beta\\sum_{j} dX_{j} \\wedge dw^{j} \\] <p>Which remains a non-degenerate symplectic form for \\(\\beta &gt; 0\\), a condition that has already been imposed. The new non-negative Poisson brackets yield:</p> \\[ \\{U, \\beta \\} = 1 \\qquad \\{w^{i}, X_{j}\\} = \\delta^{i}_j \\qquad \\{U, X_{i}\\} = -\\frac{1}{\\beta}X_{i} \\] <p>And their respective equations of motion are given by:</p> \\[  -h\\frac{dw^{i}}{dt} = \\frac{k}{\\beta} \\frac{\\partial H}{\\partial X_{i}} \\qquad -h\\frac{dX_{i}}{dt} = -\\frac{k}{\\beta} \\frac{\\partial H}{\\partial w^{i}} + \\frac{k X_{i}}{\\beta} \\frac{\\partial H}{\\partial U} \\] \\[ -h\\frac{dU}{dt} = k \\frac{\\partial H}{\\partial \\beta} - \\frac{k}{\\beta} \\sum_{j} X_{j} \\frac{\\partial H}{\\partial X_{j}} \\qquad -h\\frac{d\\beta}{dt} = -k\\frac{\\partial H}{\\partial U}  \\] <p>We will refer to these as the Hermosis equations of learning. While they can be rigorously derived from the new symplectic form, a more streamlined derivation based on the properties of Poisson brackets is provided in the Appendix.</p>"},{"location":"learning-dynamics/#integration","title":"Integration","text":"<p>The presented four equations allow us to describe the learning process of a model. Since they should be numerically integrated to perform optimization, we seek their integral form. By substituting the last equation into the second one and rearranging the terms, we obtain the evolution equation for the momentum \\(X_i\\)\u200b as</p> \\[ h\\beta \\frac{dX_{i}}{dt} + h\\frac{d\\beta}{dt} X_{i} = h \\frac{d}{dt}(\\beta X_{i}) = k\\frac{\\partial H}{\\partial w^{i}} \\] <p>Integrating over the interval \\([t\u2212\\tau,t]\\) with \\(\\tau\\) small enough to preserve quasi-static aproximation, we obtain an update rule for the momenta:</p> \\[ \\beta(t) \\mathbf{X}(t) = \\beta(t-\\tau) \\mathbf{X}(t-\\tau) -\\int_{t-\\tau}^{t} \\mathbf{F}(t') dt' \\] <p>Where \\(\\mathbf{F}\\) represents a generalized force, whose components are given by:</p> \\[ F_{i} = -\\frac{k}{h}\\frac{\\partial H}{\\partial w^{i}} \\] <p>On the other hand, integrating the first equation over the same interval, we obtain an update rule for the weights:</p> \\[ \\mathbf{w}(t) = \\mathbf{w}(t-\\tau) - \\int_{t-\\tau}^t \\mathbf{v}(t')dt' \\] <p>Where \\(\\mathbf{v}\\) denotes the learning velocity, with components:</p> \\[ v^{i} = \\frac{k}{h\\beta} \\frac{\\partial H}{\\partial X_{i}} \\] <p>This last equation tells us something important, the \\(\\beta\\) parameter determines the system's inertia throughout its evolution. Large values of \\(\\beta\\) slow down learning, while small values accelerate it.</p>"},{"location":"learning-dynamics/#application","title":"Application","text":"<p>Let us now examine the connection between the proposed dynamics and the current algorithms used in machine learning.</p> <p>In practice, a model is trained by minimizing a loss function \\(L\\), which measures the distance between a model's current state and an expected state. Drawing from classical mechanics, we propose a potential analogous to the gravitational potential:</p> \\[ V = \\frac{\\beta c^2}{k} L \\] <p>Where \\(c^2\\) with units of square energy is introduced just to ensure that \\(L\\) remains dimensionless. The choice of this potential is not arbitrary, it is based on the interpretation of the term \\(\\beta/k\\) as a thermal mass that amplifies the importance of the distance within the potential energy. Furthermore, we propose a kinetic energy in terms of a mass tensor \\(M_{ij}\\)\u200b of the form:</p> \\[ K = \\frac{1}{2} \\sum_{i j} M^{ij} Y_{i} Y_{j} = \\frac{\\beta}{2k}\\sum_{ij} g^{ij}X_{i} X_{j} = \\frac{\\beta}{2k} \\mathbf{X}^2 \\] <p>Where \\(g_{ij}\\)\u200b is a dimensionless metric tensor, which we assume for now to be constant. In this way, the Hamiltonian is defined as:</p> \\[ H = \\frac{\\beta}{2k} \\mathbf{X}^2 + \\frac{\\beta c^2}{k} L + E(U, \\beta) \\] <p>Here \\(E\\) is a function of the temperature, enabling us to specify an arbitrary thermal profile. Under this Hamiltonian, the velocity components are given by:</p> \\[ v^{i} = \\frac{k}{h\\beta} \\frac{\\partial H}{\\partial X_{i}} = \\frac{1}{h} X^{i} \\qquad  X^{i} = \\sum_{ij}g^{ij}X_j \\] <p>Applying an Euler discretization, the weight update rule can be approximated as:</p> \\[ \\mathbf{w}(t) \\approx \\mathbf{w}(t-\\tau) - \\frac{\\tau}{h} \\mathbf{X}(t) \\] <p>On the other hand, the generalized force driving the learning process has the following components:</p> \\[ F_{i} = -\\frac{\\beta c^2}{h} \\frac{\\partial L}{\\partial w^{i}}  \\] <p>By evaluating the components and performing the integration, we arrive at an expression for the impulse as a function of the loss gradient.</p> \\[ \\mathbf{I}(t) = -\\int_{t-\\tau}^t\\mathbf{F}(t') dt' = \\frac{c^2}{h} \\nabla L \\int_{t-\\tau}^t \\beta(t')dt'  \\] <p>Substituting into the momenta update rule, we obtain:</p> \\[ \\mathbf{X}(t) = \\frac{\\beta(t-\\tau)}{\\beta(t)}    \\mathbf{X}(t-\\tau) + \\frac{c^2}{h} \\left( \\frac{1}{\\beta(t)} \\int_{t-\\tau}^t \\beta(t') dt'\\right ) \\nabla L \\] <p>This tells us that the momenta are updated in terms of time averages of the thermal mass.</p>"},{"location":"learning-dynamics/#constant-temperature","title":"Constant temperature","text":"<p>Assuming a constant temperature, that is, a constant thermal mass:</p> \\[ \\beta(t) = \\beta \\] <p>We obtain a constant impulse that depends on the step size:</p> \\[ \\mathbf{I}(t) = \\frac{\\beta c^2}{h} \\nabla L \\int_{t-\\tau}^t dt' =  \\frac{\\tau c^2}{h}\\beta \\nabla L \\] <p>And the update rule will be a historical accumulation of the loss gradient:</p> \\[ \\mathbf{X}(t) = \\mathbf{X}(t-\\tau) + \\frac{\\tau c^2}{h} \\nabla L \\] <p>Under a suitable reparameterization, we recover the stochastic gradient descent or \\(\\text{SGD}\\) update rule <sup>4</sup>:</p> \\[ \\begin{aligned} \\mathbf{X}(t) = \\mathbf{X}(t-\\tau) +  \\zeta \\nabla L \\\\ \\\\ \\mathbf{w}(t) \\approx \\mathbf{w}(t-\\tau) - \\eta \\mathbf{X}(t) \\end{aligned} \\] <p>Where \\(\\eta\\) is the learning rate and \\(\\zeta\\) controls the influence of the loss gradient on the momentum.</p>"},{"location":"learning-dynamics/#harmonic-potential","title":"Harmonic potential","text":"<p>By adding a harmonic potential to the Hamiltonian such that:</p> \\[ H = \\frac{\\beta}{2k} \\mathbf{X}^2 + \\frac{\\lambda}{2} \\mathbf{w}^2 + V \\] <p>The generalized force now includes a term consistent with that used in gradient descent with weight decay <sup>5</sup>, which proposes adding a term \\(\\lambda \\mathbf{w}\\) to the loss gradient. This is because an extra term is now added to the force:</p> \\[ F_{i}' = \\lambda w_{i} \\] <p>Further physical explanations of the underlying mechanism, as well as possible corrections, are deferred to future work.</p>"},{"location":"learning-dynamics/#exponential-cooling","title":"Exponential cooling","text":"<p>Assuming that the system temperature decreases to zero exponentially, that is, an exponentially growing thermal mass, </p> \\[ \\beta(t) = \\beta e^{\\gamma t} \\] <p>We obtain an impulse given by:</p> \\[ \\mathbf{I}(t) = \\frac{\\beta c^2}{h} \\nabla L \\int_{t-\\tau}^t e^{\\gamma t'} dt' = \\frac{c^2}{h} \\frac{1-e^{-\\gamma \\tau}}{\\gamma} \\beta e^{\\gamma t} \\] <p>Then, momentum will be an exponential moving average <sup>9</sup> of the loss gradient.</p> \\[ \\mathbf{X}(t) = e^{-\\gamma \\tau} \\mathbf{X}(t-\\tau) + \\frac{1-e^{-\\gamma \\tau}}{\\gamma} \\frac{c^2}{h} \\nabla L \\] <p>The exponential moving average is biased toward zero at early times due to its initialization, therefore, a bias correction factor should be applied <sup>10</sup>:</p> \\[ \\hat{\\mathbf{X}}(t) = \\frac{\\mathbf{X}(t)}{1-e^{-\\gamma t}}  \\] <p>Under reparameterization, this recovers gradient descent with momentum and friction <sup>11</sup>:</p> \\[ \\begin{aligned} \\mathbf{X}(t) = \\mu \\mathbf{X}(t-\\tau) + (1-\\mu) \\zeta \\nabla L  \\\\ \\\\ \\mathbf{w}(t) = \\mathbf{w}(t-\\tau) - \\eta \\mathbf{X}(t) \\end{aligned} \\] <p>Most implementations of \\(\\text{SGD}\\) with momentum ignore the \\(\\gamma\\) parameter and skip the bias correction.</p>"},{"location":"learning-dynamics/#relativistic-hamiltonian","title":"Relativistic Hamiltonian","text":"<p>Lastly, we adopt a classical Hamiltonian incorporating relativistic kinetic energy, given by:</p> \\[ H = \\sqrt{\\mathbf{X}^2 + \\frac{k^2}{\\beta^2}} + V + E(U, \\beta) \\] <p>This Hamiltonian is a generalization of the previous one, since for small momenta \\(|\\mathbf{X}| \\ll k/\\beta\\), the kinetic energy can be approximated as:</p> \\[ \\sqrt{\\mathbf{X}^2+\\frac{k^2}{\\beta^2}} = \\frac{k^2}{\\beta^2} \\sqrt{\\frac{\\beta^2}{k^2}\\mathbf{X}^2 + 1} \\approx \\frac{k}{\\beta} + \\frac{\\beta}{2k}\\mathbf{X}^2 - \\frac{\\beta^3 (\\mathbf{X}^2)^2}{8k^3} + \\cdots \\] <p>The first term, \\(kT\\), corresponds to a rest energy, while higher-order terms are typically discarded. However, recent work on physics-inspired optimizers <sup>12</sup> has shown that retaining higher-order terms in the series can enhance optimization. Under a relativistic regime, the learning velocity will then be:</p> \\[ v^{i} = \\frac{k}{h\\beta} \\frac{\\partial H}{\\partial X_{i}} =  \\frac{k}{h\\beta}  \\frac{X^{i}}{ \\sqrt{\\mathbf{X}^2 + k^2/\\beta^2}} = \\frac{1}{h} \\frac{X^{i}}{\\sqrt{\\beta^2\\mathbf{X}^2/k^2 + 1}} \\] <p>If we consider \\(\\beta(t) = \\beta\\) to be constant, we recover the relativistic gradient descent <sup>13</sup>, which proposes weight updates of the form:</p> \\[ \\mathbf{w}(t) = \\mathbf{w}(t-\\tau) - \\eta \\frac{\\mathbf{X}}{ \\sqrt{\\mathbf{X}^2 + k^2/\\beta^2}} \\] <p>However, considering \\(\\beta(t) = \\beta e^{\\gamma t}\\), we observe that \\(\\mathbf{v} \\rightarrow 0\\) rapidly and the system ceases to learn. This is not an error in the theory, rather, it is due to the fact that we are working under a classical approximation in which the potential is considered decoupled from the metric tensor.</p> <p>The work of Guskov and Vanchurin on covariant gradient descent <sup>14</sup> suggests that by embedding the potential into the metric tensor, recovers adaptive momentum-based optimizers such as \\(\\text{Adam}\\) <sup>10</sup> and, as a specific case, the \\(\\text{RMSProp}\\) optimizer <sup>15</sup>. Verifying this correspondence explicitly within the current theoretical framework remains as future work.</p>"},{"location":"learning-dynamics/#conclusion","title":"Conclusion","text":"<p>The proposed formalism demonstrated that a Hamiltonian framework can recover the majority of current optimization algorithms. This approach moves beyond purely heuristic updates, offering a clear physical interpretation where:</p> <ul> <li> <p>The loss function acts as a metric distance between model's configurations.</p> </li> <li> <p>Temperature dictates the effective mass, weighting the importance of these distances.</p> </li> <li> <p>Phase space convergence is guaranteed by the evolution of internal energy.</p> </li> </ul> <p>These results lay the groundwork for a new class of physically-informed optimizers. By identifying where current classical approximations fail, such as the decoupling of the potential from the metric tensor, we open new avenues for incorporating covariant and relativistic dynamics into machine learning, potentially leading to more stable and faster convergence in complex loss landscapes.</p>"},{"location":"learning-dynamics/#citation","title":"Citation","text":"<p>This work is versioned. To cite the specific version v0.1.0, use:</p> <p>Eric Hermosis. Learning Dynamics. Version 0.1.0. 2025. DOI: 10.5281/zenodo.18071681</p> <p>To cite the work in general, including all versions, use the concept DOI: 10.5281/zenodo.18071680.</p> <p>BibTeX entry for v0.1.0:</p> <pre><code>@misc{hermosis2025learning,\n  author       = {Eric Hermosis},\n  title        = {Learning Dynamics},\n  year         = {2025},\n  version      = {v0.1.0},\n  howpublished = {\\url{https://github.com/eric-hermosis/learning-dynamics}},\n  doi          = {10.5281/zenodo.18071681},\n  note         = {GitHub repository, archived on Zenodo}\n}\n</code></pre> <ol> <li> <p>Herbert B. Callen. Thermodynamics and an Introduction to Thermostatistics. Wiley, 2 edition, 1985.\u00a0\u21a9\u21a9</p> </li> <li> <p>Ana Cannas da Silva. Lectures on Symplectic Geometry. Volume 1764 of Lecture Notes in Mathematics. Springer, 2001.\u00a0\u21a9\u21a9</p> </li> <li> <p>Vladimir I. Arnold. Mathematical Methods of Classical Mechanics. Springer, 2 edition, 1989.\u00a0\u21a9\u21a9</p> </li> <li> <p>Christopher M. Bishop and Hannah Bishop. Deep Learning: Foundations and Concepts. Springer International Publishing, Cham, 2024.\u00a0\u21a9\u21a9</p> </li> <li> <p>Anders Krogh and John A. Hertz. A simple weight decay can improve generalization. In Advances in Neural Information Processing Systems. 1992.\u00a0\u21a9\u21a9</p> </li> <li> <p>John C. Baez. What is entropy? 2024. arXiv preprint. arXiv:2409.09232.\u00a0\u21a9</p> </li> <li> <p>John M. Lee. Introduction to Smooth Manifolds. Springer, 2 edition, 2013.\u00a0\u21a9</p> </li> <li> <p>William Rowan Hamilton. On a general method in dynamics. Philosophical Transactions of the Royal Society of London, 124:247\u2013308, 1834.\u00a0\u21a9</p> </li> <li> <p>Robert G. Brown. Exponential Smoothing: Forecasting and Control. Prentice-Hall, 1956.\u00a0\u21a9</p> </li> <li> <p>Diederik P. Kingma and Jimmy Ba. Adam: a method for stochastic optimization. 2014. arXiv preprint. arXiv:1412.6980.\u00a0\u21a9\u21a9</p> </li> <li> <p>L\u00e9on Bottou. Large-scale machine learning with stochastic gradient descent. In Proceedings of COMPSTAT 2010, 177\u2013186. 2010.\u00a0\u21a9</p> </li> <li> <p>Pranav Vaidhyanathan, Lucas Schorling, Natalia Ares, and Michael A. Osborne. A physics-inspired optimizer: velocity regularized adam. 2025. arXiv preprint. arXiv:2505.13196.\u00a0\u21a9</p> </li> <li> <p>Guilherme Fran\u00e7a, Jeremias Sulam, Daniel P. Robinson, and Renato Vidal. Conformal symplectic and relativistic optimization. 2019. arXiv preprint. arXiv:1903.04100.\u00a0\u21a9</p> </li> <li> <p>Dmitry Guskov and Vitaly Vanchurin. Covariant gradient descent. 2025. arXiv preprint. arXiv:2504.05279.\u00a0\u21a9</p> </li> <li> <p>Geoffrey Hinton. Neural networks for machine learning, lecture 6e. Coursera (online course), 2012.\u00a0\u21a9</p> </li> </ol>"},{"location":"learning-dynamics/CHANGELOG/","title":"Changelog","text":"<p>All notable changes to this paper are documented in this file. </p>"},{"location":"learning-dynamics/CHANGELOG/#v011-2025-12-28","title":"[v0.1.1] \u2013 2025-12-28","text":""},{"location":"learning-dynamics/CHANGELOG/#changed","title":"Changed","text":"<ul> <li>Updated abstract for clarity.</li> <li>Renamed subsection modelling to model  </li> <li>Fix position of model subsection</li> <li>Updated Equilibrium section for clarity</li> <li>Fix bad numeration on section application</li> <li>Add subsection title \"constant temperature\"</li> <li>Add subsection title \"Harmonic potential\"</li> <li>Renamed subindex alpha to i weight decay formula</li> <li>Add subsection title \"Exponential cooling\"</li> <li>Add exponential cooling explanation</li> <li>Add bias correction explanation on SGD with momentum</li> <li>Add subsection title \"Relativistic Hamiltonain</li> <li>Fix discrepancy between article and online version</li> </ul>"},{"location":"learning-dynamics/appendix/","title":"Appendix","text":""},{"location":"learning-dynamics/appendix/#derivation-of-learning-equations","title":"Derivation of learning equations","text":"<p>The equations for the system without temperature coupling described by the variables \\(\\mathbf{Y}\\) are:</p> \\[ -h \\frac{dw^{i}}{dt} = k\\{w^{i}, H\\} = k\\frac{\\partial H}{\\partial Y_{i}} \\qquad -\\frac{dY_{i}}{dt} = k\\{Y_{i}, H  \\} = -k\\frac{\\partial H}{\\partial w^{i}} \\] \\[ -\\frac{dU}{dt} = k\\frac{\\partial H}{\\partial \\beta} \\qquad -h\\frac{d\\beta}{dt} = -k\\frac{\\partial H}{\\partial U} \\] <p>Let us now see how to derive the equations with the coupling \\(\\mathbf{Y}=\\beta \\mathbf{X}\\). From the Leibniz rule for the bracket containing the coordinates of \\(\\mathbf{Y}\\), given a Hamiltonian \\(H\\):</p> \\[ \\{Y_{i}, H\\} = \\{\\beta X_{i}, H\\} = \\beta\\{X_{i}, H\\} + X_{i}\\{\\beta, H\\} \\] <p>Given that we know:</p> \\[ \\{Y_{i}, H  \\} = -\\frac{\\partial H}{\\partial w^{i}} \\qquad  \\{\\beta, H\\} = -\\frac{\\partial H}{\\partial U} \\] <p>We substitute these values to obtain the Poisson brackets of the system in terms of the momenta \\(\\mathbf{X}\\):</p> \\[ -\\frac{\\partial H}{\\partial w^{i}} = \\beta \\{X_{i}, H\\} - X_{i} \\frac{\\partial H}{\\partial U} \\Rightarrow \\{X_{i}, H\\} = -\\frac{1}{\\beta}\\frac{\\partial H}{\\partial w^{i}} + \\frac{X_{i}}{\\beta} \\frac{\\partial H}{\\partial U} \\] <p>And we recover the proposed H-equation:</p> \\[ -h\\frac{dX_{i}}{dt} = k\\{X_{i}, H\\} = -\\frac{k}{\\beta}\\frac{\\partial H}{\\partial w^{i}} + \\frac{kX_{i}}{\\beta} \\frac{\\partial H}{\\partial U} \\] <p>In order to reconcile the evolution of the internal energy with the proposed evolution, we recall the following thermodynamic identity:</p> \\[ \\left(\\frac{\\partial H}{\\partial \\beta} \\right)_{\\mathbf{Y}} =   \\left(\\frac{\\partial H}{\\partial \\beta} \\right)_{\\mathbf{X}} + \\sum_{j} \\left(\\frac{\\partial H}{\\partial X_{j}} \\right)_{\\beta, X_{i \\neq j}} \\left(\\frac{\\partial X_{j}}{\\partial \\beta} \\right)_{\\mathbf{Y}} \\] <p>The subscripts indicate which parameters are considered constant. This notation is common in thermodynamics and was omitted from the formalism, as we specified at each step the symplectic form upon which we are working.</p> <p>Let us now consider how to find the partial derivative of the momentum with respect to the parameter \\(\\beta\\). From the coupling relation:</p> \\[ X_{i}  = \\frac{Y_{i}}{\\beta} \\Rightarrow \\frac{\\partial X_{i}}{\\partial \\beta} = -\\frac{1}{\\beta^2} Y_{i} = -\\frac{1}{\\beta} X_{i} \\] <p>We can then obtain the evolution of the internal energy:</p> \\[ -h\\frac{dU}{dt} = k\\frac{\\partial H}{\\partial \\beta} - \\frac{1}{\\beta} \\sum_{j} \\frac{\\partial H}{\\partial X_{j}}X_{j} \\] <p>For the weight-momentum brackets let us note that:</p> \\[ \\frac{\\partial H}{\\partial Y_{i}} = \\frac{\\partial H}{\\partial X_{i}} \\frac{\\partial X_{i}}{\\partial Y_{i}} = \\frac{1}{\\beta} \\frac{\\partial H}{\\partial X_{i}} \\] <p>Then:</p> \\[ -h\\frac{dw^{i}}{dt} = \\frac{k}{\\beta} \\frac{\\partial H}{\\partial X_{i}} \\] <p>Finally, the equation containing the changes of the \\(H\\) in the direction \\(\\partial/\\partial U\\) is identical, given that the variable U is not coupled in the same way as \\(\\beta\\).\"</p>"}]}